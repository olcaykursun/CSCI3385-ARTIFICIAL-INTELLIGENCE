{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 371
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 29829,
     "status": "ok",
     "timestamp": 1588415144629,
     "user": {
      "displayName": "Olcay Kursun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GituS95krCYpwh_YbfZ3E8pgbJSp1jhJlEakhpR=s64",
      "userId": "07951426947236008413"
     },
     "user_tz": 300
    },
    "id": "xa3MVOOk0Oag",
    "outputId": "bb188164-c313-464e-b694-24e8b47ea3f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               name  MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  \\\n",
      "0    phon_R01_S01_1      119.992       157.302        74.997         0.00784   \n",
      "1    phon_R01_S01_2      122.400       148.650       113.819         0.00968   \n",
      "2    phon_R01_S01_3      116.682       131.111       111.555         0.01050   \n",
      "3    phon_R01_S01_4      116.676       137.871       111.366         0.00997   \n",
      "4    phon_R01_S01_5      116.014       141.781       110.655         0.01284   \n",
      "..              ...          ...           ...           ...             ...   \n",
      "190  phon_R01_S50_2      174.188       230.978        94.261         0.00459   \n",
      "191  phon_R01_S50_3      209.516       253.017        89.488         0.00564   \n",
      "192  phon_R01_S50_4      174.688       240.005        74.287         0.01360   \n",
      "193  phon_R01_S50_5      198.764       396.961        74.904         0.00740   \n",
      "194  phon_R01_S50_6      214.289       260.277        77.973         0.00567   \n",
      "\n",
      "     MDVP:Jitter(Abs)  MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer  ...  \\\n",
      "0             0.00007   0.00370   0.00554     0.01109       0.04374  ...   \n",
      "1             0.00008   0.00465   0.00696     0.01394       0.06134  ...   \n",
      "2             0.00009   0.00544   0.00781     0.01633       0.05233  ...   \n",
      "3             0.00009   0.00502   0.00698     0.01505       0.05492  ...   \n",
      "4             0.00011   0.00655   0.00908     0.01966       0.06425  ...   \n",
      "..                ...       ...       ...         ...           ...  ...   \n",
      "190           0.00003   0.00263   0.00259     0.00790       0.04087  ...   \n",
      "191           0.00003   0.00331   0.00292     0.00994       0.02751  ...   \n",
      "192           0.00008   0.00624   0.00564     0.01873       0.02308  ...   \n",
      "193           0.00004   0.00370   0.00390     0.01109       0.02296  ...   \n",
      "194           0.00003   0.00295   0.00317     0.00885       0.01884  ...   \n",
      "\n",
      "     Shimmer:DDA      NHR     HNR  status      RPDE       DFA   spread1  \\\n",
      "0        0.06545  0.02211  21.033       1  0.414783  0.815285 -4.813031   \n",
      "1        0.09403  0.01929  19.085       1  0.458359  0.819521 -4.075192   \n",
      "2        0.08270  0.01309  20.651       1  0.429895  0.825288 -4.443179   \n",
      "3        0.08771  0.01353  20.644       1  0.434969  0.819235 -4.117501   \n",
      "4        0.10470  0.01767  19.649       1  0.417356  0.823484 -3.747787   \n",
      "..           ...      ...     ...     ...       ...       ...       ...   \n",
      "190      0.07008  0.02764  19.517       0  0.448439  0.657899 -6.538586   \n",
      "191      0.04812  0.01810  19.147       0  0.431674  0.683244 -6.195325   \n",
      "192      0.03804  0.10715  17.883       0  0.407567  0.655683 -6.787197   \n",
      "193      0.03794  0.07223  19.020       0  0.451221  0.643956 -6.744577   \n",
      "194      0.03078  0.04398  21.209       0  0.462803  0.664357 -5.724056   \n",
      "\n",
      "      spread2        D2       PPE  \n",
      "0    0.266482  2.301442  0.284654  \n",
      "1    0.335590  2.486855  0.368674  \n",
      "2    0.311173  2.342259  0.332634  \n",
      "3    0.334147  2.405554  0.368975  \n",
      "4    0.234513  2.332180  0.410335  \n",
      "..        ...       ...       ...  \n",
      "190  0.121952  2.657476  0.133050  \n",
      "191  0.129303  2.784312  0.168895  \n",
      "192  0.158453  2.679772  0.131728  \n",
      "193  0.207454  2.138608  0.123306  \n",
      "194  0.190667  2.555477  0.148569  \n",
      "\n",
      "[195 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "  from google.colab  import  drive\n",
    "  drive.mount('/content/gdrive')\n",
    "  mydirectory = 'gdrive/My Drive/Colab Notebooks/PD/'\n",
    "except:\n",
    "  mydirectory = ''\n",
    "\n",
    "#Parkinson's dataset is downloaded from UCI ML repository: https://archive.ics.uci.edu/ml/datasets/parkinsons\n",
    "fname=mydirectory+\"parkinsons.data\"       #195 rows/recordings, there are only 32 human subjects (8 of which are PD)\n",
    "data = pd.read_csv(fname)                 #6 recordings per subject (7 recordings for only 3 of the subjects)\n",
    "dataX = data.drop(columns=['status','name'])   #We have 6records*29subj + 7records*3subjects = 195\n",
    "#print the first few rows\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1585,
     "status": "ok",
     "timestamp": 1587796681870,
     "user": {
      "displayName": "Olcay Kursun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GituS95krCYpwh_YbfZ3E8pgbJSp1jhJlEakhpR=s64",
      "userId": "07951426947236008413"
     },
     "user_tz": 300
    },
    "id": "vIzib4zvUf40",
    "outputId": "9018e895-70c0-4b5d-9dde-6e3f98efa710"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found by plain_split: {'C': 2, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.67      0.78        24\n",
      "           1       0.90      0.99      0.94        74\n",
      "\n",
      "    accuracy                           0.91        98\n",
      "   macro avg       0.92      0.83      0.86        98\n",
      "weighted avg       0.91      0.91      0.90        98\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#FIRST ATTEMPT\n",
    "#NOTE THAT THIS IS NOT A GOOD FIT WITH THE DATASET, WE NEED LEAVE SUBJECT OUT INSTEAD\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Split the dataset in two equal parts\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataX, data['status'], test_size=0.5, random_state=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)   #ranges, mean, stddev of the features in the training set\n",
    "X_test = scaler.transform(X_test) \n",
    "#especially if you are going to use rbf-svm, this preprocessing step is very important\n",
    "#because SVM will be calculateing the distance of the test example to each one of the training examples\n",
    "#you dont want to have one feature ranging 100 to 200 and the other one (which is perhaps more important) ranging from 0 to 1\n",
    "#Refer to the discussion in the next code cell about what normalization is.\n",
    "\n",
    "\n",
    "\n",
    "#Now, we start training-optimizing-testing the classifier\n",
    "#Find the optimal parameters by cross-validation, well, optimal only if you do a proper cross-validation\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-2, 1e-1, 1, 10, 100],   #libsvm showed that each point has some influence around itself in the space\n",
    "                     #gamma is the inverse of the sigma of the \"sphere\"  (the mean of that sphere is on that particular training example)\n",
    "                     'C': [0.25, 0.5, 1, 2, 4, 8, 16, 32]},\n",
    "                    {'kernel': ['linear'], 'C': [0.25, 0.5, 1, 2, 4, 8, 16, 32]}]\n",
    "\n",
    "clf_plain_split = GridSearchCV(SVC(), tuned_parameters, scoring='f1_macro')  #accuracy can be bad for this dataset because it is imbalanced, we have a lot more Parkinson's subjects.\n",
    "#Here is the summary of the lecture on why the dataset is imbalanced, thus forcing us to use average of f1 scores of the classes. \n",
    "#Keep in mind the study is for telediagnosis of Parkinson's (a good story for COVID-19 era). \n",
    "#A good control group is needed, unfortunately we have only 8 healthy subjects.\n",
    "#In the video I explained why that might be in more detail, the main idea is that finding a good control group (vs Parkinson's) is not easy. \n",
    "#You cannot use students as a control group because normally they are not going to be the calling the telediagnosis service to be tested for Parkinsonism. \n",
    "#It is important to match demographic groups etc.\n",
    "\n",
    "\n",
    "clf_plain_split.fit(X_train, y_train)\n",
    "print(\"Best parameters set found by plain_split:\",clf_plain_split.best_params_)\n",
    "y_pred = clf_plain_split.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "#WOW, we get 91% accuracy\n",
    "#THAT 91% IS NOT REALISTIC THOUGH!  I EXPLAINED WHY IN THE VIDEO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1574,
     "status": "ok",
     "timestamp": 1587796681873,
     "user": {
      "displayName": "Olcay Kursun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GituS95krCYpwh_YbfZ3E8pgbJSp1jhJlEakhpR=s64",
      "userId": "07951426947236008413"
     },
     "user_tz": 300
    },
    "id": "IVIiPyotWd1X",
    "outputId": "bd3658a4-3cad-4887-d0a2-fb1f69b727fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original vs normalized values for the first feature, first 10 rows are shown:\n",
      "[[ -0.82929965 119.992     ]\n",
      " [ -0.77097169 122.4       ]\n",
      " [ -0.90947638 116.682     ]\n",
      " [ -0.90962172 116.676     ]\n",
      " [ -0.92565706 116.014     ]\n",
      " [ -0.81573501 120.552     ]\n",
      " [ -0.82263845 120.267     ]\n",
      " [ -1.13595747 107.332     ]\n",
      " [ -1.4169878   95.73      ]\n",
      " [ -1.43331382  95.056     ]]\n"
     ]
    }
   ],
   "source": [
    "#A LITTLE DISCUSSION ABOUT WHAT NORMALIZATION IS:\n",
    "#zero centered and unit standard deviation\n",
    "\n",
    "X_normalized = scaler.fit_transform(dataX)   #ranges, mean, stddev etc of the features in the training set\n",
    "print('original vs normalized values for the first feature, first 10 rows are shown:')\n",
    "print(np.concatenate((X_normalized[:10,[0]],dataX.iloc[:10,[0]]), axis=1))\n",
    "#print(X_normalized[:10,0])\n",
    "#print(dataX.iloc[:10,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11546,
     "status": "ok",
     "timestamp": 1587796691861,
     "user": {
      "displayName": "Olcay Kursun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GituS95krCYpwh_YbfZ3E8pgbJSp1jhJlEakhpR=s64",
      "userId": "07951426947236008413"
     },
     "user_tz": 300
    },
    "id": "swL4zrLCuly3",
    "outputId": "591e7ee6-9d6f-4204-b7c2-88ec3d280194"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_subjects 32\n",
      "Best parameters set found by logo_split: {'svm__C': 4, 'svm__gamma': 0.1, 'svm__kernel': 'rbf'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.42      0.40        12\n",
      "           1       0.80      0.78      0.79        36\n",
      "\n",
      "    accuracy                           0.69        48\n",
      "   macro avg       0.59      0.60      0.59        48\n",
      "weighted avg       0.70      0.69      0.69        48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "logo = LeaveOneGroupOut()\n",
    "print('N_subjects', logo.get_n_splits(dataX, data['status'],data['name'].astype(str).str[:-2]))\n",
    "\n",
    "#SPLIT INDIVIDUALS\n",
    "trains = []\n",
    "tests = []\n",
    "N_train = 0\n",
    "#logo = leave one group out (in this case a group is the set of all sound recordings that belong to one subject)\n",
    "for train_index, test_index in logo.split(dataX, data['status'], data['name'].astype(str).str[:-2]):\n",
    "    #print((train_index, test_index))\n",
    "    if np.random.random()>0.25 :      #if you use 0.5 here 16 randomly selected subjects will be placed in the training set, the rest will be placed in the test set\n",
    "        trains=np.append(trains, test_index)    #test_index is the index of all recordings for the next subject of the logo iterator\n",
    "        N_train=N_train+1\n",
    "    else :\n",
    "        tests=np.append(tests, test_index)\n",
    "\n",
    "X_train, X_test = dataX.iloc[trains,:], dataX.iloc[tests,:]\n",
    "y_train, y_test = data['status'][trains], data['status'][tests]\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'svm__kernel': ['rbf'], 'svm__gamma': [1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100],\n",
    "                     'svm__C': [0.25, 0.5, 1, 2, 4, 8, 16, 32]},\n",
    "                    {'svm__kernel': ['linear'], 'svm__C': [0.25, 0.5, 1, 2, 4, 8, 16, 32]}]\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipeline = Pipeline([('scale',StandardScaler()), ('svm',SVC())])\n",
    "\n",
    "#CROSS VALIDATION IN GRIDSEARCH BELOW IS NOT USING LEAVE SUBJECT OUT, IT USES THE STANDARD K-FOLD\n",
    "#THAT BETTER BE FIXED (FOR THE SAME REASON WHY 91% WAS NOT REALISTIC ABOVE)\n",
    "#X_train contains 16 subjects but GridSearch will split it into cv folds (cv = 5, 10 or whatever number that you choose)\n",
    "#Ideally, you want cv = 16 and you want your gridsearch split this set so that one group (=subject) is left out!\n",
    "clf_logo_split = GridSearchCV(pipeline, tuned_parameters, scoring='f1_macro', cv = N_train)\n",
    "#[([7,8,9,10,11,12.....],[1,2,3,4,5,6]),([1,2,3,4,5,6,13,14,15,...],[7,8,9,10,11,12]),(),(),...]\n",
    "#Even if cv = N_train = 16 that's not enough: Gridsearch will leave out 6 examples but they will belong to possibly different subjects\n",
    "clf_logo_split.fit(X_train, y_train)\n",
    "print(\"Best parameters set found by logo_split:\",clf_logo_split.best_params_)\n",
    "y_pred = clf_logo_split.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 21384,
     "status": "ok",
     "timestamp": 1587796701711,
     "user": {
      "displayName": "Olcay Kursun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GituS95krCYpwh_YbfZ3E8pgbJSp1jhJlEakhpR=s64",
      "userId": "07951426947236008413"
     },
     "user_tz": 300
    },
    "id": "Y6b5ZJ9-Hkyu",
    "outputId": "44787747-b002-40da-e762-fcc963f8245f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found by logo_split_logo_CV: {'svm__C': 16, 'svm__gamma': 0.001, 'svm__kernel': 'rbf'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.67        12\n",
      "           1       0.86      1.00      0.92        36\n",
      "\n",
      "    accuracy                           0.88        48\n",
      "   macro avg       0.93      0.75      0.79        48\n",
      "weighted avg       0.89      0.88      0.86        48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SIMPLY SETTING CV=16 WOULD APPLY CROSS VALIDATION WITHOUT LEAVE SUBJECT OUT\n",
    "#THE BEST SOLUTION WOULD BE TO LEAVE-SUBJECT-OUT (LOGO: LEAVE-GROUP-OUT, see the code below)\n",
    "#NOTE THAT THE BEST SOLUTION IS NOT THE ONE REPORTING THE HIGHEST ACCURACY\n",
    "#THE BEST SOLUTION IS THE MOST REALISTIC ONE, THE ONE THAT DOES NOT OVERESTIMATE THE ACCURACY\n",
    "mycv = logo.split(X_train, y_train, data['name'][trains].astype(str).str[:-2])\n",
    "clf_logo_split_logo_cv = GridSearchCV(pipeline, tuned_parameters, scoring='f1_macro', cv = mycv)\n",
    "clf_logo_split_logo_cv.fit(X_train, y_train)\n",
    "print(\"Best parameters set found by logo_split_logo_CV:\",clf_logo_split_logo_cv.best_params_)\n",
    "y_pred = clf_logo_split_logo_cv.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 492
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 21376,
     "status": "ok",
     "timestamp": 1587796701713,
     "user": {
      "displayName": "Olcay Kursun",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GituS95krCYpwh_YbfZ3E8pgbJSp1jhJlEakhpR=s64",
      "userId": "07951426947236008413"
     },
     "user_tz": 300
    },
    "id": "tsDRtmvVNu-T",
    "outputId": "b4ac2582-dc1b-4303-c4a7-baaf777c5bb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.33      0.35        12\n",
      "           1       0.78      0.81      0.79        36\n",
      "\n",
      "    accuracy                           0.69        48\n",
      "   macro avg       0.57      0.57      0.57        48\n",
      "weighted avg       0.68      0.69      0.68        48\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.42      0.40        12\n",
      "           1       0.80      0.78      0.79        36\n",
      "\n",
      "    accuracy                           0.69        48\n",
      "   macro avg       0.59      0.60      0.59        48\n",
      "weighted avg       0.70      0.69      0.69        48\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.67        12\n",
      "           1       0.86      1.00      0.92        36\n",
      "\n",
      "    accuracy                           0.88        48\n",
      "   macro avg       0.93      0.75      0.79        48\n",
      "weighted avg       0.89      0.88      0.86        48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline.named_steps['svm'].set_params(**clf_plain_split.best_params_)\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "pipeline.set_params(**clf_logo_split.best_params_)\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "pipeline.set_params(**clf_logo_split_logo_cv.best_params_)\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNznO8lukvMzeYKO0PBQ5rz",
   "collapsed_sections": [],
   "name": "parkinsons_LSO_CV.ipynb",
   "provenance": [
    {
     "file_id": "1TsxoEY193YbLq614SAoGIWT0WiN5zchc",
     "timestamp": 1586489050291
    },
    {
     "file_id": "1DZvOUTIya26PDG3ZD1GrCUSmUgF6lcv3",
     "timestamp": 1585728162799
    },
    {
     "file_id": "10DucatE9iLG1K7RJnQ2nGnrKV5hkXpol",
     "timestamp": 1585719884328
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
